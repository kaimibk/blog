---
layout: post
title:  "Chapter 1: Role of Probability Theory in Science"
categories: notes
date:   2019-10-06 12:00:00 -1000
mathjax: true
---

## (1.1) Scientific Inference

Our state of knowledge is always incomplete:
- Measurements are limited by accuracy
- More experiments could be conducted

The goal of inference is to find the truth with incomplete information

## (1.2) Inference Requires Probability Theory

In conventional statistics, the probability is defined as as the frequency of an event&mdash;the "frequentist" perspective.

In the frequentist view, probabilities are restricted to random variables, quantities that can meaningfully vary through a series of repeated experiments.

- $$p(A)$$ : frequency with which A occurs in identical repeats of an experiment

Recently, a new perspective finds that probability theory goes beyond finding the frequency of random variables. Rather, it is a logical framework for conducting inference about hypothesis&mdash;Bayesian probability theory.

This allows us to compute the probability of a theory or model parameter, which frequentist statistics fails to do directly.

- $$p(A \mid B)$$ : a real number measure of the plausibility of a proposition A, given (conditional on) the truth of the information represented by proposition B.


### (1.2.1) : The Two Rules for Manipulating Probabilities

**Sum Rule**
$$p(A \mid B) + p(\sim A \mid B) = 1$$

**Product Rule**

$$p(A,B \mid C)=p(A \mid C)p(B \mid A, C)=p(B \mid C)p(A \mid B,C)$$

where the term $$Pr(A \mid B)$$ can be interpreted as the probability of the truth of proposition $$A$$, given (conditional on) the truth of the information represented by proposition $$B$$. Bayes Theorem then follows from the product rule by rearranging the middle and right equations,

$$p(A \mid B,C)= \frac{p(A \mid C) p(B \mid A,C)}{p(B \mid C)}$$

## (1.3) : Usual Form of Bayes' Theorem

$$p(H_i \mid D, I)=(p(H_i│I)p(D \mid H_i,I))/(p(D \mid I))$$
- $$H_i$$ : proposition asserting the truth of a hypothesis.
- $$I$$ : proposition representing our prior information.
- $$D$$ : proposition representing data.
- $$p(D│H_i,I)$$ : probability of obtaining the data, $$D$$, if $$H_i$$  and $$I$$ are true. Also called the likelihood.
- $$p(H_i│I)$$ : prior probability of the hypothesis.
- $$p(H_i│D,I)$$ : posterior probability of $$H_i$$.
- $$p(D│I)= \sum_i  p(H_i│I)p(D│H_i,I)$$ : normalization factor.

### (1.3.1) Discrete Hypothesis Space

In Bayesian inference, we seek to assign probabilities to competing hypotheses, forming a hypothesis space. In the Hubble example, the hypothesis space is discrete and comprised of two elements, $$H_1$$, accelerating, and $$H_2$$, decelerating. In the example of a discrete hypothesis space, $$p(H_i \mid D, I)$$ is called a probability distribution. As always, the probabilities must be properly normalized,

$$\sum_{i=1}^{2} p(H_i \mid D, I) = 1$$

### (1.3.2) Continuous Hypothesis Space

In contrast, we can also work with a continuous hypothesis space. Again, in the Hubble example, estimating $$H_0$$ is called a parameter estimation model&mdash;where the hypothesis space is continuous. In this example, the proposition $$H_0$$ asserts that the true value of the Hubble constant is in the interval $$[h, h+dh]$$. This can be represented by the $$p(H_0 \mid D, I) dH_0$$, where $$p(H_0 \mid D, I)$$ is a probability density function (PDF), which is defined as,

$$p(H_0 \mid D, I) = \lim_{\delta h \to 0} \frac{p(h \le H_0 < h + \delta h \mid D, I>)}{\delta h}$$

Letting $$W$$ be a proposition asserting $$H_0 \in [a, b]$$,

$$p(W \mid D, I) = \int_a^b p(H_0 \mid D, I) dH_0$$

And, as always, the probability must be normalized,

$$\int_{\Delta H} p(H \mid D, I) dH = 1$$

where $$\Delta H$$ indicates the hypothesis space.

In the case where a combination of two variables are discrete/continuous we can construct a joint probability distribution, $$p(X, Y \mid D, I)$$. When both are continuous,

$$p(X, Y, \mid D, I) = \lim_{\delta x, \delta y \to 0} \frac{p(x \le X < x + \delta x, y \le Y < y + \delta y \mid D, I)}{\delta x \delta y}$$

### (1.3.3) Bayes' Theorem&mdash;Model of the Learning Process

In Bayesian inference, we are interested in arriving at some hypothesis (with some level of plausability) conditional on our state of knowledge. We do this by encoding our prior state of knowledge into prior probability distribution, $$p(H_0, I)$$. In parameters estimation, a Bayesian PDF is a metric which reflects our state of knowledge (or ignorance) about the parameter of interest.

When we aquire new data, $$D_1$$, Baye's theorem allows us to _update_ our state of knowledge with the likelihood function, to arrive at a posterior probability density function, $p(H_0 \mid D_1, I)$. That is to say,

$$p(H_0 \mid D_1, I) \propto p(H_0 \mid I) p(D_1 | H, I)$$

_Note_, the "$$\propto$$" is indicated because the posterior probabilities are missing a normalization constant. This is generally okay in practice, such as with maximum a posteriori (MAP) estimation, because the constant is always positive and does not depend on the parameter of interest, therefore plays no role in the optimization.

Now, suppose we obtained more data, $$D_2$$. This time, our prior knowledge, $$I'$$, is the posterior derived from $$D_1$$&mdash; $$I' = D_1, I$$. The new posterior is given by,

$$p(H_0 \mid D_2, I') \propto p(H_0 \mid I') p(D_2 \mid H_0, I')$$

### (1.3.4) Example of the Use of Bayes' Theorem