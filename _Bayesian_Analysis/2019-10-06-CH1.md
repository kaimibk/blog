---
layout: post
title:  "Chapter 1: Role of Probability Theory in Science"
categories: notes
date:   2019-10-06 12:00:00 -1000
mathjax: true
---

## (1.1) Scientific Inference

Our state of knowledge is always incomplete:
- Measurements are limited by accuracy
- More experiments could be conducted

The goal of inference is to find the truth with incomplete information

## (1.2) Inference Requires Probability Theory

In conventional statistics, the probability is defined as as the frequency of an event&mdash;the "frequentist" perspective.

In the frequentist view, probabilities are restricted to random variables, quantities that can meaningfully vary through a series of repeated experiments.

- $$p(A)$$ : frequency with which A occurs in identical repeats of an experiment

Recently, a new perspective finds that probability theory goes beyond finding the frequency of random variables. Rather, it is a logical framework for conducting inference about hypothesis&mdash;Bayesian probability theory.

This allows us to compute the probability of a theory or model parameter, which frequentist statistics fails to do directly.

- $$p(A \mid B)$$ : a real number measure of the plausibility of a proposition A, given (conditional on) the truth of the information represented by proposition B.


### (1.2.1) : The Two Rules for Manipulating Probabilities

**Sum Rule**

$$p(A \mid B) + p(\sim A \mid B) = 1$$

**Product Rule**

$$p(A,B \mid C)=p(A \mid C)p(B \mid A, C)=p(B \mid C)p(A \mid B,C)$$

where the term $$Pr(A \mid B)$$ can be interpreted as the probability of the truth of proposition $$A$$, given (conditional on) the truth of the information represented by proposition $$B$$. Bayes Theorem then follows from the product rule by rearranging the middle and right equations,

$$p(A \mid B,C)= \frac{p(A \mid C) p(B \mid A,C)}{p(B \mid C)}$$

## (1.3) : Usual Form of Bayes' Theorem

$$p(H_i \mid D, I)=(p(H_i│I)p(D \mid H_i,I))/(p(D \mid I))$$
- $$H_i$$ : proposition asserting the truth of a hypothesis.
- $$I$$ : proposition representing our prior information.
- $$D$$ : proposition representing data.
- $$p(D│H_i,I)$$ : probability of obtaining the data, $$D$$, if $$H_i$$  and $$I$$ are true. Also called the likelihood.
- $$p(H_i│I)$$ : prior probability of the hypothesis.
- $$p(H_i│D,I)$$ : posterior probability of $$H_i$$.
- $$p(D│I)= \sum_i  p(H_i│I)p(D│H_i,I)$$ : normalization factor.

### (1.3.1) Discrete Hypothesis Space

In Bayesian inference, we seek to assign probabilities to competing hypotheses, forming a hypothesis space. In the Hubble example, the hypothesis space is discrete and comprised of two elements, $$H_1$$, accelerating, and $$H_2$$, decelerating. In the example of a discrete hypothesis space, $$p(H_i \mid D, I)$$ is called a probability distribution. As always, the probabilities must be properly normalized,

$$\sum_{i=1}^{2} p(H_i \mid D, I) = 1$$

### (1.3.2) Continuous Hypothesis Space

In contrast, we can also work with a continuous hypothesis space. Again, in the Hubble example, estimating $$H_0$$ is called a parameter estimation model&mdash;where the hypothesis space is continuous. In this example, the proposition $$H_0$$ asserts that the true value of the Hubble constant is in the interval $$[h, h+dh]$$. This can be represented by the $$p(H_0 \mid D, I) dH_0$$, where $$p(H_0 \mid D, I)$$ is a probability density function (PDF), which is defined as,

$$p(H_0 \mid D, I) = \lim_{\delta h \to 0} \frac{p(h \le H_0 < h + \delta h \mid D, I>)}{\delta h}$$

Letting $$W$$ be a proposition asserting $$H_0 \in [a, b]$$,

$$p(W \mid D, I) = \int_a^b p(H_0 \mid D, I) dH_0$$

And, as always, the probability must be normalized,

$$\int_{\Delta H} p(H \mid D, I) dH = 1$$

where $$\Delta H$$ indicates the hypothesis space.

In the case where a combination of two variables are discrete/continuous we can construct a joint probability distribution, $$p(X, Y \mid D, I)$$. When both are continuous,

$$p(X, Y, \mid D, I) = \lim_{\delta x, \delta y \to 0} \frac{p(x \le X < x + \delta x, y \le Y < y + \delta y \mid D, I)}{\delta x \delta y}$$

### (1.3.3) Bayes' Theorem&mdash;Model of the Learning Process

In Bayesian inference, we are interested in arriving at some hypothesis (with some level of plausability) conditional on our state of knowledge. We do this by encoding our prior state of knowledge into prior probability distribution, $$p(H_0, I)$$. In parameters estimation, a Bayesian PDF is a metric which reflects our state of knowledge (or ignorance) about the parameter of interest.

When we aquire new data, $$D_1$$, Baye's theorem allows us to _update_ our state of knowledge with the likelihood function, to arrive at a posterior probability density function, $p(H_0 \mid D_1, I)$. That is to say,

$$p(H_0 \mid D_1, I) \propto p(H_0 \mid I) p(D_1 | H, I)$$

_Note_, the "$$\propto$$" is indicated because the posterior probabilities are missing a normalization constant. This is generally okay in practice, such as with maximum a posteriori (MAP) estimation, because the constant is always positive and does not depend on the parameter of interest, therefore plays no role in the optimization.

Now, suppose we obtained more data, $$D_2$$. This time, our prior knowledge, $$I'$$, is the posterior derived from $$D_1$$&mdash; $$I' = D_1, I$$. The new posterior is given by,

$$p(H_0 \mid D_2, I') \propto p(H_0 \mid I') p(D_2 \mid H_0, I')$$

### (1.3.4) Example of the Use of Bayes' Theorem

Let $$I$$ represent,

1. Model $$M_1$$ predicts a star's distance, $$d_1=100$$ light years (ly)
2. Model $$M_2$$ predicts a star's distance, $$d_2=200$$ ly
3. The uncertainty, $$e$$, in distance measurements is described by a Gaussian distribution of the form,

$$p(e \mid I) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{e^2}{2\sigma^2}\right)$$

where $$\sigma=40$$ ly.
4. There is no basis for preferring $$M_1$$ over $$M_2$$, so we set $$p(M_1 \mid I) = p(M_2 \mid I) = 0.5$$

Let $$D \equiv$$ "The measured distance $$d=120$$ ly."

Using this information, we construct Baye's theorem for each hypothesis,

$$p(M_1 \mid D, I) = \frac{p(M_1 | I)p(D | M_1, I)}{p(D | I)}$$

$$p(M_2 \mid D, I) = \frac{p(M_12| I)p(D | M_2, I)}{p(D | I)}$$

Since we are interested in comparing the two models, we can contruct the odds ratio,

$$O_{12} = \frac{p(M_1 \mid D, I)}{p(M_2 \mid D, I)} = \frac{p(M_1 \mid I)p(D \mid M_1, I)}{p(M_2 \mid I)p(D \mid M_2, I)} = \frac{p(D \mid M_1, I)}{p(D \mid M_2, I)}$$

Since we are under the assumption that the only reason the measured value $$d$$ can differ from the prediction $$d_1$$ is because of measurement uncertainties, $$e$$. Thus, we write $$d = d_1 + e \Rightarrow e = d - d_1$$. With this, we can write the likelihood for the first model,

$$p(D \mid M_1, I) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(d-d_1)^2}{2\sigma^2}\right)$$

which, when plugging in values, numerically equals $$0.00880$$. Similarly, for the second model,

$$p(D \mid M_2, I) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(d-d_2)^2}{2\sigma^2}\right)$$

which equates to $$0.00135$$. Which, when using our expression for the odd's ratio, comes out to $$6.52$$ in favor of model $$M_1$$.

## (1.4) Probability and Frequency

- Probability: a representation of our state of knowledge
- Frequency: a factual property that is measured/estimated

Probabilities change when we change our state of knowledge; frequencies do not.

### (1.4.1) Example: Incorporating Frequency Information

- False positive rate: 2.3%
- False negative rate: 1.4% (i.e; 98.6% reliable base on testing of people who actually have the disease)
- Define $$UD$$ as a new unknown disease
- Assume the incidence of the disease in a random sample of the region is $$1 : 10^{4}$$

Furthermore, let us define the following:
- $$H \equiv$$ "You have UD."
- $$\bar{H} \equiv$$ "You do not have UD."
- $$D_1 \equiv$$ "You test positive for UD."
- $$I_1 \equiv$$ \{"No known cause for the UD", $$p(D \mid H, I_1) = 0.986$$, $$p(D \mid \bar{H}, I_1) = 0.023$$, "incidence of UD in the population is $$1:10^{4}$$\}

First, start by writing Bayes' theorem,

$$p(D \mid D_1, I_1) = \frac{p(H \mid I_1)p(D_1 \mid H, I_1)}{p(D_1 \mid I_1)}$$

Since the denominator is a normalization constant, we can write,

$$p(D_1 \mid I_1) = p(H \mid I_1)p(D_1 \mid H, I_1) + p(\bar{H} \mid I_1)p(D_1 \mid \bar{H}, I_1)$$

to be continued...